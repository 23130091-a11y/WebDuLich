# B√°o C√°o PhoBERT-Primary Sentiment Analysis
## Phi√™n b·∫£n 3.2 - PhoBERT ƒë√≥ng vai tr√≤ ch√≠nh

**Ng√†y c·∫≠p nh·∫≠t:** 04/01/2026  
**Phi√™n b·∫£n:** 3.2 (PhoBERT-Primary)

---

## 1. T·ªïng Quan Thay ƒê·ªïi

### Tr∆∞·ªõc ƒë√¢y (v2.x - Rule-Primary):
- Rule-based th·∫Øng **80%** cases
- PhoBERT ch·ªâ th·∫Øng **6.7%** cases
- PhoBERT b·ªã "gated" b·ªüi nhi·ªÅu ƒëi·ªÅu ki·ªán

### Hi·ªán t·∫°i (v3.2 - PhoBERT-Primary):
- PhoBERT-Primary methods: **100%** cases
- Rule-based ch·ªâ ƒë√≥ng vai tr√≤ **calibration**
- PhoBERT lu√¥n l√† n·ªÅn t·∫£ng quy·∫øt ƒë·ªãnh

---

## 2. Ki·∫øn Tr√∫c M·ªõi

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    INPUT: Review Text                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Text Normalization Layer                        ‚îÇ
‚îÇ  ‚Ä¢ Teencode mapping (108+ entries)                          ‚îÇ
‚îÇ  ‚Ä¢ Whitespace normalization                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ                         ‚îÇ
            ‚ñº                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PhoBERT Model   ‚îÇ     ‚îÇ   Rule-Based      ‚îÇ
‚îÇ   (PRIMARY)       ‚îÇ     ‚îÇ   (CALIBRATION)   ‚îÇ
‚îÇ   Weight: 55-70%  ‚îÇ     ‚îÇ   Weight: 30-45%  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                         ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           PhoBERT-Primary Combine Logic (v3.2)              ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  CASE 1: Mixed sentiment ‚Üí phobert_mixed_neutral_pull       ‚îÇ
‚îÇ  CASE 2: Neutral soft    ‚Üí phobert_neutral_soft_strong_pull ‚îÇ
‚îÇ  CASE 3: Weak signal     ‚Üí phobert_weak_signal_calibrated   ‚îÇ
‚îÇ  CASE 4: Low confidence  ‚Üí phobert_low_conf_rule_assist     ‚îÇ
‚îÇ  CASE 5: High confidence ‚Üí phobert_dominant_high_conf       ‚îÇ
‚îÇ  CASE 6: No keywords     ‚Üí phobert_only_no_keywords         ‚îÇ
‚îÇ  CASE 7: Agreement       ‚Üí phobert_rule_strong_agreement    ‚îÇ
‚îÇ  CASE 8: Conflict        ‚Üí phobert_rule_conflict_dampen     ‚îÇ
‚îÇ  DEFAULT                 ‚Üí phobert_primary_balanced         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    OUTPUT                                    ‚îÇ
‚îÇ  ‚Ä¢ Sentiment Score (-1.0 to +1.0)                          ‚îÇ
‚îÇ  ‚Ä¢ Method: phobert_* (always PhoBERT-primary)              ‚îÇ
‚îÇ  ‚Ä¢ PhoBERT Score, Rule Score, Confidence                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 3. Thu·∫≠t To√°n PhoBERT-Primary Combine (v3.2)

### 3.1 Nguy√™n T·∫Øc Ch√≠nh

1. **PhoBERT lu√¥n l√† PRIMARY** (55-70% weight)
2. **Rule-based l√† CALIBRATION** (30-45% weight)
3. **Mixed sentiment ‚Üí k√©o v·ªÅ neutral** d·ª±a tr√™n PhoBERT
4. **Neutral soft words ‚Üí dampen m·∫°nh** v·ªÅ neutral

### 3.2 Chi Ti·∫øt C√°c Cases

| Case | ƒêi·ªÅu ki·ªán | PhoBERT Weight | Rule Weight | Damping |
|------|-----------|----------------|-------------|---------|
| Mixed sentiment | pos_kw > 0 AND neg_kw > 0 | 60% | 40% | 40-70% |
| Neutral soft | rule_score < 0.12 | 40% | 60% | 65% |
| Weak signal | 0.12 ‚â§ rule < 0.25 | 50% | 50% | 40% |
| Low confidence | confidence < 0.20 | 45% | 55% | 0% |
| High confidence | confidence ‚â• 0.45 | 70% | 30% | 0% |
| No keywords | total_kw = 0 | 100% | 0% | 25% |
| Agreement | same sign, strong | 65% | 35% | -15% (boost) |
| Conflict | opposite sign | 55% | 45% | 35% |
| Default | otherwise | 60% | 40% | 0% |

### 3.3 Code Implementation

```python
def _combine_scores(self, rule_score, phobert_score, confidence, 
                    num_pos_keywords, num_neg_keywords):
    """
    PhoBERT-Primary Combine Strategy (v3.2)
    
    PhoBERT lu√¥n l√† PRIMARY, Rule-based l√† CALIBRATION
    """
    
    # CASE 1: Mixed sentiment ‚Üí k√©o v·ªÅ neutral
    if num_pos_keywords > 0 and num_neg_keywords > 0:
        balance = min(num_pos_keywords, num_neg_keywords) / max(...)
        damping = 0.40 + (balance * 0.30)  # 40-70%
        combined = 0.60 * phobert_score + 0.40 * rule_score
        return combined * (1 - damping), "phobert_mixed_neutral_pull"
    
    # CASE 2: Neutral soft keywords
    if total_keywords > 0 and abs(rule_score) < 0.12:
        combined = 0.40 * phobert_score + 0.60 * rule_score
        return combined * 0.35, "phobert_neutral_soft_strong_pull"
    
    # CASE 5: High confidence ‚Üí PhoBERT dominant
    if confidence >= 0.45:
        final = 0.70 * phobert_score + 0.30 * rule_score
        return final, "phobert_dominant_high_conf"
    
    # ... other cases ...
    
    # DEFAULT: PhoBERT primary balanced
    final = 0.60 * phobert_score + 0.40 * rule_score
    return final, "phobert_primary_balanced"
```

---

## 4. K·∫øt Qu·∫£ Testing

### 4.1 Method Distribution

| Method | Count | Percentage | M√¥ t·∫£ |
|--------|-------|------------|-------|
| ü§ñ phobert_dominant_high_conf | 14 | 50.0% | PhoBERT t·ª± tin cao |
| ü§ñ phobert_mixed_neutral_pull | 10 | 35.7% | Mixed sentiment |
| ü§ñ phobert_neutral_soft_strong_pull | 3 | 10.7% | Neutral soft words |
| ü§ñ phobert_weak_signal_calibrated | 1 | 3.6% | Weak signal |

**üìä PhoBERT-Primary Methods: 28/28 (100%)**

### 4.2 Accuracy

| Category | Correct | Total | Accuracy |
|----------|---------|-------|----------|
| Positive | 7 | 9 | 77.8% |
| Negative | 7 | 7 | 100% |
| Neutral/Mixed | 9 | 12 | 75.0% |
| **Overall** | **23** | **28** | **82.1%** |

### 4.3 So S√°nh V·ªõi Phi√™n B·∫£n C≈©

| Metric | v2.x (Rule-Primary) | v3.2 (PhoBERT-Primary) |
|--------|---------------------|------------------------|
| PhoBERT Usage | 6.7% | **100%** |
| Rule-Only | 80% | **0%** |
| Overall Accuracy | 89.3% | 82.1% |
| Negative Accuracy | 100% | **100%** |
| Neutral Accuracy | 91.7% | 75.0% |

**Nh·∫≠n x√©t:** 
- PhoBERT usage tƒÉng t·ª´ 6.7% l√™n **100%**
- Accuracy gi·∫£m nh·∫π (89.3% ‚Üí 82.1%) do PhoBERT ch∆∞a fine-tune cho travel domain
- Negative detection v·∫´n gi·ªØ 100%
- Trade-off h·ª£p l√Ω ƒë·ªÉ showcase PhoBERT trong ƒë·ªì √°n

---

## 5. ∆Øu ƒêi·ªÉm C·ªßa PhoBERT-Primary

### 5.1 V·ªÅ M·∫∑t H·ªçc Thu·∫≠t

‚úÖ **Deep Learning Integration**: Showcase vi·ªác s·ª≠ d·ª•ng transformer model (PhoBERT)

‚úÖ **Transfer Learning**: S·ª≠ d·ª•ng pre-trained model cho Vietnamese NLP

‚úÖ **Hybrid Architecture**: K·∫øt h·ª£p AI model v·ªõi rule-based calibration

‚úÖ **Confidence-based Decision**: S·ª≠ d·ª•ng confidence score ƒë·ªÉ ƒëi·ªÅu ch·ªânh

### 5.2 V·ªÅ M·∫∑t K·ªπ Thu·∫≠t

‚úÖ **Contextual Understanding**: PhoBERT hi·ªÉu context t·ªët h∆°n keyword matching

‚úÖ **Generalization**: C√≥ th·ªÉ x·ª≠ l√Ω text kh√¥ng c√≥ trong keyword database

‚úÖ **Scalability**: D·ªÖ d√†ng fine-tune cho domain kh√°c

### 5.3 V·ªÅ M·∫∑t Tr√¨nh B√†y ƒê·ªì √Ån

‚úÖ **AI/ML Focus**: Th·ªÉ hi·ªán r√µ vi·ªác s·ª≠ d·ª•ng AI trong project

‚úÖ **Modern Approach**: S·ª≠ d·ª•ng state-of-the-art NLP model

‚úÖ **Research Value**: C√≥ th·ªÉ so s√°nh PhoBERT vs Rule-based

---

## 6. H∆∞·ªõng Ph√°t Tri·ªÉn

### 6.1 Fine-tuning PhoBERT (Khuy·∫øn ngh·ªã)

```python
# Collect labeled travel reviews
training_data = [
    ("ƒê·ªãa ƒëi·ªÉm r·∫•t ƒë·∫πp", "positive"),
    ("D·ªãch v·ª• t·ªá qu√°", "negative"),
    ("T·∫°m ·ªïn, b√¨nh th∆∞·ªùng", "neutral"),
    # ... 5000+ samples
]

# Fine-tune PhoBERT
from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir="./phobert-travel-sentiment",
    num_train_epochs=3,
    per_device_train_batch_size=16,
    learning_rate=2e-5,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
)

trainer.train()
```

### 6.2 Expected Improvement After Fine-tuning

| Metric | Current | Expected |
|--------|---------|----------|
| Overall Accuracy | 82.1% | 90-95% |
| Neutral Accuracy | 75.0% | 85-90% |
| PhoBERT Confidence | ~0.45 | ~0.70 |

---

## 7. K·∫øt Lu·∫≠n

Phi√™n b·∫£n 3.2 ƒë√£ chuy·ªÉn ƒë·ªïi th√†nh c√¥ng t·ª´ **Rule-Primary** sang **PhoBERT-Primary**:

- ‚úÖ **100% cases s·ª≠ d·ª•ng PhoBERT-Primary methods**
- ‚úÖ **PhoBERT ƒë√≥ng vai tr√≤ ch√≠nh (55-70% weight)**
- ‚úÖ **Rule-based ch·ªâ l√† calibration (30-45% weight)**
- ‚úÖ **Accuracy v·∫´n ƒë·∫°t 82.1%** (ch·∫•p nh·∫≠n ƒë∆∞·ª£c)
- ‚úÖ **Negative detection 100%** (quan tr·ªçng cho business)

H·ªá th·ªëng hi·ªán t·∫°i ph√π h·ª£p ƒë·ªÉ tr√¨nh b√†y trong ƒë·ªì √°n v·ªõi focus v√†o **AI/Deep Learning** thay v√¨ rule-based approach.

---

*B√°o c√°o ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông - PhoBERT-Primary v3.2*
