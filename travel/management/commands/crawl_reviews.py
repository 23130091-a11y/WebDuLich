"""
Script crawl ƒë√°nh gi√° t·ª´ Google Maps
L∆∞u √Ω: C·∫ßn c√†i ƒë·∫∑t th√™m: pip install selenium beautifulsoup4 lxml
"""

from django.core.management.base import BaseCommand
from travel.models import Destination, Review
from travel.ai_module import analyze_sentiment
import time
import random

class Command(BaseCommand):
    help = 'Crawl ƒë√°nh gi√° t·ª´ Google Maps (c·∫ßn c√†i selenium)'

    def add_arguments(self, parser):
        parser.add_argument(
            '--destination-id',
            type=int,
            help='ID c·ªßa ƒë·ªãa ƒëi·ªÉm c·∫ßn crawl reviews'
        )
        parser.add_argument(
            '--max-reviews',
            type=int,
            default=20,
            help='S·ªë l∆∞·ª£ng reviews t·ªëi ƒëa c·∫ßn crawl'
        )

    def handle(self, *args, **options):
        try:
            from selenium import webdriver
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from selenium.webdriver.chrome.options import Options
            from bs4 import BeautifulSoup
        except ImportError:
            self.stdout.write(self.style.ERROR(
                '‚ùå Ch∆∞a c√†i ƒë·∫∑t th∆∞ vi·ªán c·∫ßn thi·∫øt!\n'
                'Ch·∫°y l·ªánh: pip install selenium beautifulsoup4 lxml'
            ))
            return

        destination_id = options.get('destination_id')
        max_reviews = options.get('max_reviews')

        if not destination_id:
            self.stdout.write(self.style.ERROR(
                '‚ùå Vui l√≤ng ch·ªâ ƒë·ªãnh --destination-id\n'
                'VD: python manage.py crawl_reviews --destination-id=1'
            ))
            return

        try:
            destination = Destination.objects.get(id=destination_id)
        except Destination.DoesNotExist:
            self.stdout.write(self.style.ERROR(f'‚ùå Kh√¥ng t√¨m th·∫•y ƒë·ªãa ƒëi·ªÉm v·ªõi ID {destination_id}'))
            return

        self.stdout.write(f'üîç B·∫Øt ƒë·∫ßu crawl reviews cho: {destination.name}')
        self.stdout.write(f'üìç V·ªã tr√≠: {destination.location}')

        # T·∫°o search query cho Google Maps
        search_query = f"{destination.name} {destination.location} Vietnam"
        google_maps_url = f"https://www.google.com/maps/search/{search_query.replace(' ', '+')}"

        # C·∫•u h√¨nh Chrome headless
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--lang=vi')
        chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')

        self.stdout.write('üåê ƒêang m·ªü tr√¨nh duy·ªát...')

        try:
            driver = webdriver.Chrome(options=chrome_options)
            driver.get(google_maps_url)
            
            # ƒê·ª£i trang load
            time.sleep(3)

            # Click v√†o k·∫øt qu·∫£ ƒë·∫ßu ti√™n
            try:
                first_result = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href*="/maps/place/"]'))
                )
                first_result.click()
                time.sleep(2)
            except:
                self.stdout.write(self.style.WARNING('‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ƒë·ªãa ƒëi·ªÉm tr√™n Google Maps'))
                driver.quit()
                return

            # Scroll ƒë·ªÉ load reviews
            self.stdout.write('üìú ƒêang load reviews...')
            reviews_panel = driver.find_element(By.CSS_SELECTOR, 'div[role="main"]')
            
            for _ in range(5):  # Scroll 5 l·∫ßn
                driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', reviews_panel)
                time.sleep(1)

            # Parse HTML
            soup = BeautifulSoup(driver.page_source, 'lxml')
            
            # T√¨m c√°c review elements
            review_elements = soup.find_all('div', {'data-review-id': True})
            
            if not review_elements:
                self.stdout.write(self.style.WARNING('‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y reviews'))
                driver.quit()
                return

            self.stdout.write(f'‚úì T√¨m th·∫•y {len(review_elements)} reviews')

            crawled_count = 0
            for review_elem in review_elements[:max_reviews]:
                try:
                    # L·∫•y t√™n ng∆∞·ªùi ƒë√°nh gi√°
                    author_elem = review_elem.find('div', class_='d4r55')
                    author_name = author_elem.text if author_elem else 'Anonymous'

                    # L·∫•y rating (s·ªë sao)
                    rating_elem = review_elem.find('span', {'role': 'img', 'aria-label': True})
                    if rating_elem:
                        rating_text = rating_elem.get('aria-label', '')
                        # Extract s·ªë t·ª´ "5 sao" ho·∫∑c "5 stars"
                        rating = int(''.join(filter(str.isdigit, rating_text.split()[0])))
                    else:
                        rating = 5

                    # L·∫•y n·ªôi dung review
                    comment_elem = review_elem.find('span', class_='wiI7pd')
                    comment = comment_elem.text if comment_elem else ''

                    if not comment:
                        continue

                    # Ph√¢n t√≠ch sentiment
                    sentiment_score, pos_keywords, neg_keywords = analyze_sentiment(comment)

                    # Ki·ªÉm tra xem review ƒë√£ t·ªìn t·∫°i ch∆∞a (tr√°nh duplicate)
                    existing = Review.objects.filter(
                        destination=destination,
                        author_name=author_name,
                        comment=comment
                    ).exists()

                    if not existing:
                        Review.objects.create(
                            destination=destination,
                            author_name=author_name,
                            rating=rating,
                            comment=comment,
                            sentiment_score=sentiment_score,
                            positive_keywords=pos_keywords,
                            negative_keywords=neg_keywords
                        )
                        crawled_count += 1
                        self.stdout.write(f'  ‚úì {author_name}: {rating}‚≠ê - {comment[:50]}...')

                except Exception as e:
                    self.stdout.write(f'  ‚ö†Ô∏è L·ªói parse review: {str(e)}')
                    continue

            driver.quit()

            self.stdout.write(self.style.SUCCESS(f'\n‚úÖ Crawl th√†nh c√¥ng {crawled_count} reviews!'))
            self.stdout.write('üí° Ch·∫°y l·ªánh sau ƒë·ªÉ t√≠nh ƒëi·ªÉm g·ª£i √Ω:')
            self.stdout.write('   python manage.py calculate_scores')

        except Exception as e:
            self.stdout.write(self.style.ERROR(f'‚ùå L·ªói: {str(e)}'))
            if 'driver' in locals():
                driver.quit()
